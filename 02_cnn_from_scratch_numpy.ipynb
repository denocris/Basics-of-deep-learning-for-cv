{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_cnn_from_scratch_numpy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denocris/Basics-of-deep-learning-for-cv/blob/main/02_cnn_from_scratch_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj8auSeb0UI5"
      },
      "source": [
        "<h1><center>  Building a CNN from Scratch  </center></h1>\n",
        "\n",
        "<center>  <img src=\"https://drive.google.com/uc?export=view&id=14NR1ZtJRXsncnS6lah_T6k7u4g-BTNT2\"width=\"800\">  </center> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdpNbcvL-tVj"
      },
      "source": [
        "## About this Lecture (Notebook Nr. 2)\n",
        "\n",
        "In lecture nr. 1, we learned how to write from scratch convolutional layers using basics mathematics and NumPy. In the same philosophy, we will build a simple convolutional neural network from scratch (this must be done at least once in a lifetime). To keep things simple, our CNN is will be composed by:\n",
        "\n",
        "* $3\\times 3$ matrix as an input image;\n",
        "* a convolutional layer with kernel size 2, stride 1. As activation function we choose or a scaled version of the sigmoid function, $\\tanh(x)$, or a relu, $\\text{max}(0,x)$;\n",
        "* a fully connected layer on top of the convolutional layer with a logistic activation function: $f(x) = \\frac{1}{1+\\exp{(-x)}}$.\n",
        "\n",
        "In modern deep learning frameworks, such as PyTorch or TensorFlow, you only have to implement the forward pass, and the framework takes care of the backward pass. Then, it automatically computes derivatives with respect to the cost to update the parameters. The backward pass could be complicated to implement from scratch except for simple architecture like the CNN described above. In this notebook, we will write from scratch every step, from the forward to the backward pass. This could sound a bit pedant, but it is useful to understand a lot of details on deep learning basic mechanisms.\n",
        "\n",
        "\n",
        "## Tools used \n",
        "\n",
        "In the first part of this notebook, we will just use numpy library for most of our computations. Only in the second part we will introduce PyTorch and use it to reproduce and check all the results computed in the first part. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2JEYq5k1LJR"
      },
      "source": [
        "## Convolution and Activation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2UPu_GS3jdd"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PfnYd0q3rtG"
      },
      "source": [
        "We copy below the convolutional function learned during the first notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwssz-jM-NIP"
      },
      "source": [
        "def convolution2d(X, K):\n",
        "    # transform in numpy array\n",
        "    X = np.array(X)\n",
        "    K = np.array(K)\n",
        "    # K dimensions\n",
        "    h, w = K.shape\n",
        "    # initialize the output (stride is 1)\n",
        "    Y = np.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
        "    for i in range(Y.shape[0]): #loop on rows\n",
        "        for j in range(Y.shape[1]): # loop on columns\n",
        "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzoUTBzv4HFF"
      },
      "source": [
        "As we saw during the first lecture, convolutions are linear operations. Therefore, to solve non-linear problems (99% of real-world problems) we need non-linear activation functions. There are plenty of activation functions in the literature. The choice of the more suited activation function for a network or a specific layer depends on many factors, such as the task itself. In this course, we will not deal with these design settings. For this exercise, we will use some common choice: *logistic sigmoid activation function* and *hyperbolic tangent activation function*. They have similar properties and, for this reason, the latter is often called *scaled sigmoid*. \n",
        "\n",
        "These functions:\n",
        "\n",
        "* are non linear in nature;\n",
        "\n",
        "* they have activations bounded;\n",
        "\n",
        "* between $x$ values $-2$ to $2$, $y$ values are very steep. Which means, any small changes in the values of $x$ in that region will cause values of $y$ to change significantly. Outside this range, $y$ values tend to respond very less to changes in $x$. This can cause an effect named *vanishing of gradients*;\n",
        "\n",
        "* tend to bring the activations to either side of the curve. In particular when used in the last layer, they are suited for binary classifiation problems making clear distinctions on prediction.\n",
        "\n",
        "\n",
        "We will also consider the widely used *ReLu activation* (Rectified Linear Unit). It is also a non-linear function, but it is not bounded. This means it can blow up the activation. Moreover, it is worth highlighting the sparsity of its activation. If we consider a neural network with a lot of neurons, using a *sigmoid* or *tanh* will cause almost all neurons to fire in an analog way. That means almost all activations will be taken into account and processed to describe the output of a network. We say that the activation is dense. This could be costly. Ideally, we would want a few neurons in the network to not activate and thereby making the activations sparse and efficient.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSmQz07_-PvF"
      },
      "source": [
        "# Scaled Sigmoid Activation Function\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "# Its derivative\n",
        "def d_tanh(x):\n",
        "    return 1 - np.tanh(x) ** 2\n",
        "\n",
        "# Logistic Activation Function\n",
        "def logistic(x):\n",
        "    return 1/(1 + np.exp(-1*x))\n",
        "# Its derivative\n",
        "def d_logistic(x):\n",
        "    return logistic(x) * ( 1 - logistic(x) )\n",
        "\n",
        "# ReLu Activation Function\n",
        "def relu(x):\n",
        "  return (np.abs(x) + x)*0.5\n",
        "# Its derivative\n",
        "def d_relu(x):\n",
        "    x= np.array(x)\n",
        "    return np.where(x > 0, 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMNmcg367EFP",
        "outputId": "8f0a4448-cfa2-49b4-8ee1-c32848b3e55c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "# evenly sampled time at 200ms intervals\n",
        "t = np.arange(-3., 3., 0.01)\n",
        "\n",
        "# red dashes, blue squares and green triangles\n",
        "plt.plot(t, tanh(t), 'b--', label='tanh')\n",
        "plt.plot(t, logistic(t), 'r--', label='logistic sigmoid')\n",
        "plt.plot(t, relu(t), 'g--', label='ReLu')\n",
        "\n",
        "\n",
        "plt.title(\"Simple Plot\")\n",
        "\n",
        "plt.axvline(0)\n",
        "plt.axhline(0)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgQXyF5FrQE-"
      },
      "source": [
        "## Generate a Simple Training Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psEs3NJ9VeDF"
      },
      "source": [
        "Let us define our simple dataset, composed by four different images of zeros and ones (black and white pixels). For technical reasons, we do not choose exactly zero as the black value but a small number called `zz`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhfbuj1lsRTW"
      },
      "source": [
        "zz = 0.001 #0.01\n",
        "np.random.seed(172) \n",
        "\n",
        "\n",
        "# Input Images\n",
        "x1 = np.array([[zz,zz,zz],[zz,zz,zz],[zz,zz,zz]])\n",
        "x2 = np.array([[zz,zz,zz],[1,1,1],[zz,zz,zz]])\n",
        "x3 = np.array([[1,1,1],[zz,zz,zz],[1,1,1]])\n",
        "x4 = np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
        "\n",
        "# dataset\n",
        "dataset = [x1,x2,x3,x4]\n",
        "\n",
        "# labels\n",
        "Y = np.array([[0.53],[0.77],[0.88],[1.0]])\n",
        "\n",
        "# Convolutional kernel weights\n",
        "W = np.random.randn(2,2) #* 4\n",
        "#W = np.array([[1,2],[3,4]])\n",
        "# Dense layer weights\n",
        "V = np.random.randn(4,1) #* 4\n",
        "#V = np.array([[1],[2],[3],[4]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fREe3I7X_CHW"
      },
      "source": [
        "## Mathematical Derivation of Backpropagation\n",
        "\n",
        "In machine learning, backpropagation is a widely used algorithm in training feedforward neural networks for supervised learning. The backpropagation algorithm works by computing the gradient of the loss function with respect to each weight by the chain rule, computing the gradient one layer at a time, iterating backward from the last layer. When gradients are computed, weights can be updated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F45ffwA0ekK"
      },
      "source": [
        "#### **Math Description of our CNN**\n",
        "\n",
        "Let us dive a bit into the mathematics of CNN, whose structure will be composed by\n",
        "\n",
        "* a convolutional layer with kernel size 2, stride 1;\n",
        "* a scaled version sigmoid function, $\\tanh(x)$;\n",
        "* a fully connected layer with a logistic activation function: $f(x) = \\frac{1}{1+\\exp{(-x)}}$.\n",
        "\n",
        "If $X$ is the $3\\times3 $ matrix with entries $x_{ij}$ and $W_1$ the convolutional $2 \\times 2$ filter with entries $w_{ij}$, the result of their convolution, named $\\text{conv}(X,W_1)$, is\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$\\begin{bmatrix} x_{11} & x_{12} & x_{13} \\\\  x_{21} & x_{22} & x_{23} \\\\ x_{31} & x_{32} & x_{33} \\end{bmatrix} \n",
        "\\, * \\, \\begin{bmatrix} w_{11} & w_{12} \\\\ w_{21} & w_{22}  \\end{bmatrix} \n",
        "\\,=\\,  \\begin{bmatrix} L_{11} & L_{12} \\\\ L_{21} & L_{22} \\end{bmatrix},$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "which is a $(2,2)$ tensor, i.e a matrix. Just to remind, $L_{11}=x_{11}w_{11}+x_{12}w_{12}+x_{21}w_{21}+x_{22}w_{22}$. It is convinient to reshape the result into a $(1,4)$ tensor\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$ L_1 = [L_{11}, L_{12}, L_{21}, L_{22}]$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "Now we apply the scaled sigmoid activation function $L_1^A =\\tanh(L_1)$, obtaining the output of the first layer $L_1^A$. The second layer is a fully connected (or dense) layer, which output is $L_2^A = \\sigma(L_2)$, being $L_2 = L_1^A \\cdot V$. The vector $V$ contains the weights of the second layer and $\\sigma(\\cdot)$ is the logistic activation function. $L_2$ is a scalar, being the output of a scalar product of two vectors.\n",
        "Summarizing the structure of our simple CNN, we have\n",
        "\n",
        "\\\\\n",
        "\n",
        "* $L_1 = \\text{conv} (X, W)$, first layer (convolutional), shape (1,4)\n",
        "\n",
        "* $L_1^A =\\tanh(L_1)$, first layer activation (sigmoid), shape (1,4)\n",
        "\n",
        "* $L_2 = L_1^A \\cdot V$, second layer (dense), scalar\n",
        "\n",
        "* $L_2^A = \\sigma(L_2)$, second layer activation (logistic), scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emBAUBTy0pop"
      },
      "source": [
        "### Gradient Computation: Backpropagation\n",
        "\n",
        "The loss function of our model will be the mean square error, that in the case when the `batch_size = 1` is\n",
        "$$C(w) = (L_2^A - Y)^2$$\n",
        "\n",
        "Now we will compute its derivative with respect to the model weights.\n",
        "\n",
        "#### **Derivatives with respect to the second layer**\n",
        "\n",
        "Let us start to compute the gradient of the cost function $C(w)$ with respect to $V$, the second layer weights:\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$\\frac{d C}{d V} = \\frac{d C}{d L_2^A} \\, \\frac{d L_2^A}{d L_2} \\, \\frac{d L_2}{d V} = 2 (L_2^A - Y) \\, [ \\sigma(L_2) (1- \\sigma(L_2))] \\, L_1^A \\,,$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "where to be as clear as possible with the code we define\n",
        "\n",
        "\\\\\n",
        "\n",
        "* $\\text{dC_dL2A} = 2 (L_2^A - Y) $\n",
        "*  $\\text{dL2A_dL2} = [ \\sigma(L_2) (1- \\sigma(L_2))]$\n",
        "* $\\text{dL2_dV}=  L_1^A $\n",
        "\n",
        "\n",
        "```\n",
        "dC_dL2A = 2.0*(layer_2_act - Y[2]) # scalar \n",
        "dL2A_dL2 = d_logistic(layer_2) # scalar\n",
        "dL2_dV = layer_1_act_vec # (1, 4)\n",
        "Grad_V =  dC_dL2A * dL2A_dL2 * dL2_dV  # (1,4)\n",
        "\n",
        "V = V - Grad_V.T * learning_rate\n",
        "```\n",
        "\n",
        "#### **Derivatives with respect to the first layer**\n",
        "\n",
        "Let us now compute the gradient of the cost function $C(w)$ with respect to $W_1$, the first layer weights. We explicitly compute the derivative of $C$ with respect to $w_{11}$ :\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$\\frac{d C}{d w_{11}} = \\frac{d C}{d L_2^A} \\, \\frac{d L_2^A}{d L_2} \\, \\frac{d L_2}{d L_1^A} \\, \\frac{d L_1^A}{d L_1} \\, \\frac{d L_1}{d w_{11}} = 2(L_2^A - Y) \\, [ \\sigma(L_2) (1- \\sigma(L_2))] \\, V \\, (1-\\tanh (L_1)^2) \\, \\frac{d L_1}{d w_{11}}.$$\n",
        "\n",
        "\\\\\n",
        "\n",
        "Defing $g = 2 (L_2^A - Y) \\, [ \\sigma(L_2) (1- \\sigma(L_2))]$ and reminding that $L_1$ is a vector\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$ \\frac{d C}{d w_{11}} =  g \\,  V \\,\\left[ (1-\\tanh (L_{11})^2), (1-\\tanh (L_{12})^2), (1-\\tanh (L_{21})^2),g(1-\\tanh (L_{22})^2) \\right]\\, \\left[ \\frac{d L_{11}}{d w_{11}}, \\frac{d L_{12}}{d w_{11}}, \\frac{d L_{11}}{d w_{21}} , \\frac{d L_{22}}{d w_{11}}\\right]\\,, $$  \n",
        "\n",
        "\\\\\n",
        "\n",
        "where  being that  $\\left[ \\frac{d L_{11}}{d w_{11}}, \\frac{d L_{12}}{d w_{11}}, \\frac{d L_{11}}{d w_{21}} , \\frac{d L_{22}}{d w_{11}}\\right] = [x_{11}, x_{12}, x_{21}, x_{22}]$ \n",
        "\n",
        "\\\\\n",
        "\n",
        "$$ \\frac{d C}{d w_{11}} = g \\,  V \\, \\left[ (1-\\tanh (L_{11})^2), (1-\\tanh (L_{12})^2), (1-\\tanh (L_{21})^2), (1-\\tanh (L_{22})^2) \\right] \\, [ x_{11}, x_{12}, x_{21}, x_{22}] $$  \n",
        "\n",
        "\\\\\n",
        "\n",
        "The same procedure can be applied to the derivatives with respect to the other weights. Then, one can easily realize that the gradient of $C$ with respect to weights of the first layer is nothing else than a convolution between the image $X$ and $g (1-\\tanh (L_1)^2)$\n",
        "\n",
        "\\\\\n",
        "\n",
        "$$ \\begin{bmatrix} \\frac{d C}{d w_{11}} & \\frac{d C}{d w_{12}}  \\\\ \\frac{d C}{d w_{21}} & \\frac{d C}{d w_{22}}  \\end{bmatrix} \n",
        "\\,=\\,  \\begin{bmatrix} x_{11} & x_{12} & x_{13} \\\\  x_{21} & x_{22} & x_{23} \\\\ x_{31} & x_{32} & x_{33} \\end{bmatrix} \n",
        "\\, * \\, \\begin{bmatrix} g (1-\\tanh (L_{11})^2) & g (1-\\tanh (L_{12})^2) \\\\ g (1-\\tanh (L_{21})^2)  & g (1-\\tanh (L_{22})^2)   \\end{bmatrix}  $$\n",
        "\n",
        "\n",
        "In our code, these quantities will be defined as\n",
        "\n",
        "```\n",
        "g = 2*(dC_dL2A * dL2A_dL2).dot(V.T) #(1,1).dot((1,4)) = (1,4)\n",
        "dL1A_dL1 = d_tanh(layer_1) # (2,2)\n",
        "dL1_dW = dataset[2]  # (3,3)\n",
        "```\n",
        "\n",
        "As last step, it is useful to reshape from (1,4) to (2,2) the vector `g` \n",
        "\n",
        "```\n",
        "g_reshape = np.reshape(g,(2,2)) # (2,2)\n",
        "dL1A_dL1 = d_tanh(layer_1) # (2,2)\n",
        "\n",
        "dL1_dW = dataset[2] # (3,3)\n",
        "Grad_W = convolution2d(dL1_dW, g_reshape * dL1A_dL1) # (2,2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbzTOGIXATgs"
      },
      "source": [
        "## Model Definition and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFkIbwpjP5VK"
      },
      "source": [
        "A typical training procedure for a neural network is as follows:\n",
        "\n",
        "- Define the neural network that has some learnable parameters, called wieghts;\n",
        "- iterate over a dataset of inputs;\n",
        "- process input through the network (forward pass);\n",
        "- compute the loss (how far is the output from being correct);\n",
        "- propagate gradients back into the networks parameters (backward pass);\n",
        "- update the weights of the network, typically using a simple update rule:\n",
        "  ``weight = weight - learning_rate * gradient``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v34-i_95cIp3"
      },
      "source": [
        "ACT = 'tanh' \n",
        "\n",
        "def model(image_id):\n",
        "    # first layer (conv layer)\n",
        "    layer_1 = convolution2d(dataset[image_id], W)\n",
        "    # activation function\n",
        "    layer_1_act = tanh(layer_1) if ACT == 'tanh' else relu(layer_1) # shape (2,2)\n",
        "    # reshape first layer output\n",
        "    layer_1_act_vec = np.expand_dims(np.reshape(layer_1_act,-1),axis=0) # shape (1,4)\n",
        "\n",
        "    # second layer (dense layer)\n",
        "    layer_2 = layer_1_act_vec.dot(V) # (1,4) dot (4,1) -> scalar\n",
        "    # activation function\n",
        "    layer_2_act = logistic(layer_2)\n",
        "    return layer_2_act\n",
        "\n",
        "# compute model output on image 0 before training\n",
        "init_model_pred_numpy = model(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP2ekRC3KL4t",
        "outputId": "7bdeb34e-e86c-4a61-959a-552f797dcec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_model_pred_numpy "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49876831]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTiP5FqVqwls",
        "outputId": "468af0de-3ce0-4465-aa11-0820ed704cac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "# Settings\n",
        "num_epoch = 100\n",
        "learning_rate = 0.5\n",
        "\n",
        "# Choose activation function\n",
        "ACT = 'tanh'\n",
        "\n",
        "cost_before_train, cost_after_train = 0, 0\n",
        "\n",
        "final_out, start_out = np.array([[]]),np.array([[]])\n",
        "\n",
        "# Cost before training\n",
        "for i in range(len(dataset)):\n",
        "    \n",
        "    model_pred = model(i)\n",
        "    \n",
        "    # loss function\n",
        "    cost = pow((model_pred - Y[i]),2).sum() * 0.25\n",
        "    cost_before_train = cost_before_train + cost\n",
        "    start_out = np.append(start_out, model_pred)\n",
        "\n",
        "\n",
        "# ----- TRAINING -------\n",
        "for iter in range(num_epoch):\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "\n",
        "        # ---------- Neural Network ---------------\n",
        "        # first layer\n",
        "        layer_1 = convolution2d(dataset[i],W)\n",
        "        # activation function\n",
        "        layer_1_act = tanh(layer_1) if ACT == 'tanh' else relu(layer_1) # shape (2,2)\n",
        "        # reshape first layer output\n",
        "        layer_1_act_vec = np.expand_dims(np.reshape(layer_1_act,-1), axis=0) # shape (1,4)\n",
        "\n",
        "        # second layer\n",
        "        layer_2 = layer_1_act_vec.dot(V) # (1,4) dot (4,1) -> scalar\n",
        "        # activation function\n",
        "        model_pred = logistic(layer_2)\n",
        "        # -----------------------------------------\n",
        "\n",
        "        # cost function\n",
        "        cost = pow((model_pred - Y[i]),2).sum() \n",
        "\n",
        "\n",
        "        # ---------- Backpropagation ---------------\n",
        "        dC_dL2A = 2*(model_pred - Y[i]) # scalar # model_pred = layer_2_act\n",
        "        dL2A_dL2 = d_logistic(layer_2) # scalar\n",
        "        dL2_dV = layer_1_act_vec # (1, 4)\n",
        "        Grad_V =  dC_dL2A * dL2A_dL2 * dL2_dV  \n",
        "\n",
        "        g = (dC_dL2A * dL2A_dL2).dot(V.T) #(1,1).dot((1,4)) = (1,4)\n",
        "        \n",
        "        \n",
        "        dL1A_dL1 = d_tanh(layer_1) if ACT == 'tanh' else d_relu(layer_1) # shape (2,2)\n",
        "        \n",
        "        dL1_dW = dataset[i]\n",
        "\n",
        "        g_reshape = np.reshape(g,(2,2))\n",
        "        dL1A_dL1 = d_tanh(layer_1) # (2,2)\n",
        "        dL1_dW = dataset[i]\n",
        "        Grad_W = convolution2d(dL1_dW, g_reshape * dL1A_dL1)\n",
        "\n",
        "        # ---------- Weights Update ---------------\n",
        "        W = W - Grad_W * learning_rate\n",
        "        V = V - Grad_V.T * learning_rate\n",
        "\n",
        "\n",
        "# ---- Cost after training ------\n",
        "for i in range(len(dataset)):\n",
        "\n",
        "    model_pred = model(i)\n",
        "\n",
        "    cost = pow((model_pred - Y[i]),2).sum() * 0.25\n",
        "    cost_after_train = cost_after_train + cost\n",
        "    final_out = np.append(final_out,model_pred)\n",
        "\n",
        "\n",
        "# ----- Print Results ---\n",
        "print(\"\\nW :\",W, \"\\n\\nV :\", V)\n",
        "print(\"----------------\")\n",
        "print(\"Cost before Training: \",cost_before_train)\n",
        "print(\"Cost after Training: \",cost_after_train)\n",
        "print(\"----------------\")\n",
        "print(\"Start Output : \", start_out)\n",
        "print(\"Final Output : \", final_out)\n",
        "print(\"Ground Truth  : \", Y.T)\n",
        "print(\"Diff  : \", final_out - Y.T)\n",
        "\n",
        "W_numpy, V_numpy = W, V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "W : [[ 0.18719648 -2.1564865 ]\n",
            " [ 0.40404502 -0.25352101]] \n",
            "\n",
            "V : [[-1.12665231]\n",
            " [-1.20578496]\n",
            " [-0.13551446]\n",
            " [-1.48128048]]\n",
            "----------------\n",
            "Cost before Training:  0.45964206899148174\n",
            "Cost after Training:  0.00033220053076344974\n",
            "----------------\n",
            "Start Output :  [0.49876831 0.13724093 0.17536692 0.03010256]\n",
            "Final Output :  [0.50179567 0.77048201 0.88130672 0.97694836]\n",
            "Ground Truth  :  [[0.53 0.77 0.88 1.  ]]\n",
            "Diff  :  [[-0.02820433  0.00048201  0.00130672 -0.02305164]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n0k2xk6z800"
      },
      "source": [
        "That is super! We have just built from scratch a simple but complete convolutional neural network using only numpy and basic python functions. Our next step will be to code the same minimal neural network but exploiting PyTorch.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvvlXl0cCX_i"
      },
      "source": [
        "## PyTorch Warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuDWTUz5Ft1T"
      },
      "source": [
        "PyTorch is amongst the most widely used libraries for performing machine learning research and numerical computations. PyTorch is similar to NumPy, with the additional benefit that PyTorch allows you to perform your computations on CPUs and GPUs without any change to your code. PyTorch also makes it easy to distribute your computation across multiple devices or machines. One of the most important features of PyTorch is automatic differentiation. It allows computing the gradients of your functions analytically in an efficient manner which is crucial for training machine learning models using gradient descent method. \n",
        "\n",
        "So, we will now see these PyTorch useful classes (from PyTorch Tutorials):\n",
        "\n",
        "  -  ``torch.Tensor`` - A *multi-dimensional array* with support for autograd\n",
        "     operations like ``backward()``. Also *holds the gradient* w.r.t. the\n",
        "     tensor.\n",
        "  -  ``nn.Module`` - Neural network module. *Convenient way of\n",
        "     encapsulating parameters*, with helpers for moving them to GPU,\n",
        "     exporting, loading, etc.\n",
        "  -  ``nn.Parameter`` - A kind of Tensor, that is *automatically\n",
        "     registered as a parameter when assigned as an attribute to a*\n",
        "     ``Module``.\n",
        "  -  ``autograd.Function`` - Implements *forward and backward definitions\n",
        "     of an autograd operation*. Every ``Tensor`` operation creates at\n",
        "     least a single ``Function`` node that connects to functions that\n",
        "     created a ``Tensor`` and *encodes its history*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UuTS05oKKD8"
      },
      "source": [
        "### Tensors Basis\n",
        "\n",
        "Tensors are simply multidimensional arrays\n",
        "\n",
        "* A scalar (a number) is a $0-dim$ array;\n",
        "* a vector is a $1-dim$ array;\n",
        "* a matrix is a $2-dim$ array;\n",
        "* ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4V6Ie6OMoB2"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RoM8DevMzqj",
        "outputId": "410648aa-dbc1-4f4f-f906-1af3a8c2db06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "s = torch.tensor(1)\n",
        "v = torch.tensor([1,2,3])\n",
        "m = torch.tensor([[1,2], [3,4]])\n",
        "t = torch.tensor([[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]])\n",
        "\n",
        "print(s)\n",
        "print(v)\n",
        "print(m)\n",
        "print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1)\n",
            "tensor([1, 2, 3])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[[ 1,  2,  3],\n",
            "         [ 4,  5,  6]],\n",
            "\n",
            "        [[ 7,  8,  9],\n",
            "         [10, 11, 12]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-j26Q7hPzdg"
      },
      "source": [
        "We can extract the size of the tensor by simply"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfovTKBTNKEk",
        "outputId": "709bc46c-06c2-4249-9c81-71b1896a6ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "s.size(), v.size(), m.size(), t.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([]), torch.Size([3]), torch.Size([2, 2]), torch.Size([2, 2, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yKkxGU0P78b"
      },
      "source": [
        "We can also generate a random vector of arbitrary size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VShwK4mQBif",
        "outputId": "2be73302-e5a7-4f3b-b3b3-06e5fd0c102a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "d = torch.rand([2, 2, 2])\n",
        "d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4235, 0.6670],\n",
              "         [0.2222, 0.3949]],\n",
              "\n",
              "        [[0.5163, 0.9313],\n",
              "         [0.9348, 0.7980]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WpeUB-9QP08"
      },
      "source": [
        "When you have more than one tensor you can perform algebric operations (and then convert it to a numpy array)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i2pi381QX_Z",
        "outputId": "b34611db-62fb-492a-9609-160aeb99db61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "x = torch.randn([3, 5])  # random normal\n",
        "y = torch.randn([5, 4])\n",
        "z = x @ y # matrix multiplication\n",
        "\n",
        "print(z.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.2723956   0.05799705 -0.8286556   0.2691786 ]\n",
            " [-2.0337021   1.7422463  -0.15035552 -1.9155627 ]\n",
            " [-0.33266476 -0.13925168  0.16327095  1.4322754 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCOfSQU3AJvb",
        "outputId": "360772df-e7ef-4103-8c9f-1b9e6ece8ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPa71oqwB2Qr"
      },
      "source": [
        "### Automatic Differentiation\n",
        "\n",
        "One of the advantage of PyTorch over NumPy is its automatic differentiation which is very useful in optimization applications, such as neural network backpropagation. \n",
        "\n",
        "#### Example 1 (simple)\n",
        "\n",
        "Suppose to have a composite function which is a chain of two functions: g(u(x)). To compute the derivative of g with respect to x we can use the chain rule: \n",
        "\n",
        "$$\\frac{dg}{dx} = \\frac{dg}{du} \\cdot \\frac{du}{dx}$$\n",
        "\n",
        "PyTorch can analytically compute the derivatives for us.\n",
        "\n",
        "To compute the derivatives in PyTorch first we create a tensor and set its `requires_grad = true`. We can use tensor operations to define our functions. Let us give the following example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHtiQO2cFNRc"
      },
      "source": [
        "x = torch.tensor(0.5, requires_grad=True)\n",
        "\n",
        "def u(x):\n",
        "  return x * x\n",
        "\n",
        "def g(u):\n",
        "  return -2*u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncOlMx8GFfyK"
      },
      "source": [
        "Our composite function is $g(x) = -2 x^2$, whose derivative is $dg/dx = - 4 x$. At the point $x = 0.5$ its value is $-2$. Let us check this result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrpBOHtYGGiK",
        "outputId": "f65edb61-094a-4c6c-8a84-6077318e9541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dg_dx = torch.autograd.grad(g(u(x)), x)[0]\n",
        "print(dg_dx) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qejkRnZHGkpo"
      },
      "source": [
        "#### Example 2\n",
        "\n",
        "Assume that we have samples from a curve (say $f(x) = 3x^2 + 5$) and we want to estimate f(x) based on these samples. We define a parametric function $g(x, w) = w_0 x^2 + w_1 x + w_2$, which is a function of the input x and parameters w. The goal is then to find the parameters such that $g(x, w)  f(x)$. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lWG9bd1MDba",
        "outputId": "dfc57f54-9d31-4a15-9131-03e607b0cd4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# Assuming we know that the desired function is a polynomial of 2nd degree, we\n",
        "# allocate a vector of size 3 to hold the coefficients and initialize it with\n",
        "# random noise.\n",
        "w = torch.tensor(torch.randn([3, 1]), requires_grad=True)\n",
        "\n",
        "# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.\n",
        "opt = torch.optim.Adam([w], 0.1)\n",
        "\n",
        "def model(x):\n",
        "  f = torch.stack([x*x, x , torch.ones_like(x)], 1)\n",
        "  pred = torch.squeeze(f @ w, 1)\n",
        "  return pred\n",
        "\n",
        "def compute_loss(y, pred):\n",
        "    # The loss is defined to be the mean squared error distance between our\n",
        "    # estimate of y and its true value. \n",
        "    loss = torch.nn.functional.mse_loss(y, pred)\n",
        "    return loss\n",
        "\n",
        "def data_generator():\n",
        "  # Generate some training data (between -10 and 10) based on the true function\n",
        "  x = torch.rand(100) * 20 - 10\n",
        "  y = 3*x*x + 5  \n",
        "  return x, y\n",
        "\n",
        "def train_step():\n",
        "  x, y = data_generator()\n",
        "\n",
        "  pred = model(x)\n",
        "\n",
        "  loss = compute_loss(y, pred)\n",
        "\n",
        "  opt.zero_grad()\n",
        "  loss.backward()\n",
        "  opt.step()\n",
        "\n",
        "for _ in range(1000):\n",
        "    train_step()\n",
        "\n",
        "print(w.detach().numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 3.002180e+00]\n",
            " [-6.964267e-04]\n",
            " [ 4.872326e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdnb0cxE8ioc"
      },
      "source": [
        "## PyTorch CNN Implementation I (Custom Version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVWAJPQMdwse"
      },
      "source": [
        "The main goal of this section is to warm up with PyTorch and more in general the standard pipeline to build a model and its training. We will code exactly the same problem we just solved above but in a PyTorch fashioned way.\n",
        "\n",
        "To find the same results, first we must initialize the weights with the same values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYBZsNBEAHQV"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl_iXpWgnVgu"
      },
      "source": [
        "#### Convolutions Comparison: our `convolution2d()` vs `F.conv2d()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHnSc9Xmf8ic"
      },
      "source": [
        "Let us check that our 2d-convolution written above in numpy will give us the same results of the built-in PyTorch 2d-convolution `F.conv2d()`. We will not use immediatly `F.conv2d()`, but later on. However, now it is the right time to check it gives the same output of our `convolution2d()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3aOH0gaSb4A"
      },
      "source": [
        "# Select the same seed\n",
        "np.random.seed(172)\n",
        "#torch.manual_seed(172)\n",
        "\n",
        "# Convolutional kernel weights\n",
        "W = np.random.randn(2,2) #random normal\n",
        "# Dense layer weights\n",
        "V = np.random.randn(4,1)\n",
        "\n",
        "# Convolution\n",
        "conv_numpy = convolution2d(dataset[2], W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmurH1NXgy0m"
      },
      "source": [
        "Now let us compute the PyTorch implementation of the 2d-convolution operation. It is important to\n",
        "\n",
        "* Transform numpy tensors in **torch.tensors**;\n",
        "* set the correct shape (view in PyTorch) for our tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awQJn_Xgb8ya"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# we must transform all numpy tensors in pytorch tensors\n",
        "dataset = torch.tensor(dataset, device=device, dtype=dtype)\n",
        "Y = torch.tensor(Y, device=device, dtype=dtype)\n",
        "W = torch.tensor(W, device=device, dtype=dtype, requires_grad=True)\n",
        "V = torch.tensor(V, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "# we must reshape tensors according to\n",
        "# image input must be of shape (batch, in_channel, h, w)\n",
        "# kernel must be of shape (out_channel, in_channel, h, w)\n",
        "image = dataset[2].view(1, 1, 3, 3)\n",
        "W = W.view(1,1,2,2)\n",
        "\n",
        "# Convolution\n",
        "conv_pytorch = F.conv2d(image, W)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTDpbc15nfdH"
      },
      "source": [
        "Let us compute their differece and see that it is close to zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9TROc4ilnSR"
      },
      "source": [
        "diff = conv_numpy - conv_pytorch.detach().numpy()\n",
        "\n",
        "assert all(v <= 1e-5 for v in diff.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttNq4-ldrBqa"
      },
      "source": [
        "**About detach...**\n",
        "\n",
        "In order to enable automatic differentiation, PyTorch keeps track of all operations involving tensors for which the gradient may need to be computed (i.e., `require_grad = True`). The operations are recorded as a directed graph. The detach() method constructs a new view on a tensor which is declared not to need gradients, i.e., it is to be excluded from further tracking of operations, and therefore the subgraph involving this view is not recorded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdaPEZrsqycn"
      },
      "source": [
        "#### Custom PyTorch Layers: Convolutional and Linear Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2fZDNfdhbwy"
      },
      "source": [
        "Now we will build our custom convolutional layer. We want to be sure to reproduce the same results of the previous numpy approach. For this reason we set the same seed. Since numpy and PyTorch have different random generators, we will\n",
        "\n",
        "* use numpy.random function to generate the initial weights;\n",
        "* we will convert them in torch.tensors with **torch.from_numpy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUTeSeTcnuaH"
      },
      "source": [
        "np.random.seed(172)\n",
        "torch.manual_seed(172)\n",
        "\n",
        "# Convolutional kernel weights\n",
        "kernel_h, kernel_w = 2, 2\n",
        "W = np.random.randn(kernel_h, kernel_w)\n",
        "# Dense layer weights\n",
        "size_in, size_out = 4, 1\n",
        "V = np.random.randn(4,1)\n",
        "\n",
        "class MyConv2dLayer(nn.Module):\n",
        "    \"\"\" Custom Conv layer\"\"\"\n",
        "    def __init__(self, kernel_h = 2, kernel_w = 2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_h, self.kernel_w = kernel_h, kernel_w\n",
        "\n",
        "        # to keep control of the seed, import weight from numpy\n",
        "        self.W  = nn.Parameter(torch.from_numpy(W).float(), requires_grad=True)\n",
        "\n",
        "        # otherwise this is the correct weights init\n",
        "        #weights = torch.tensor(self.kernel_h, self.kernel_w)\n",
        "        #self.W = nn.Parameter(weights, requires_grad=True)\n",
        "        #torch.nn.init.normal_(self.W, mean=0.0, std=1.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        W = self.W.view(1, 1, self.kernel_h, self.kernel_w)\n",
        "        out  = F.conv2d(x, W)\n",
        "        return out\n",
        "\n",
        "conv = MyConv2dLayer(kernel_h, kernel_w)\n",
        "\n",
        "# check that we obtain the same result\n",
        "diff = conv(image) - conv_pytorch \n",
        "\n",
        "assert all(v <= 1e-5 for v in diff.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkBNOZQxrIxY"
      },
      "source": [
        "When you build a custom layer (or model), using `nn.Module` you can take advantage of the already present methods. Then, let us check the parameters of `MyConvLayer()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei8nIxJB2Jc1",
        "outputId": "e2621704-ef8c-4ae7-9540-66e136624204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "list(conv.parameters()), W"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([Parameter containing:\n",
              "  tensor([[ 1.1561, -1.1876],\n",
              "          [ 0.9290,  0.2715]], requires_grad=True)],\n",
              " array([[ 1.15609793, -1.18758506],\n",
              "        [ 0.92901938,  0.27145336]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6DXaTR8kwAZ"
      },
      "source": [
        "Now it is the turn of the custom linear layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPHESgNLxFYr",
        "outputId": "4ff910eb-8a20-46f9-d85d-c5fccd0db364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class MyLinearLayer(nn.Module):\n",
        "    \"\"\" Custom Linear layer\"\"\"\n",
        "    def __init__(self, size_in = size_in, size_out = size_out):\n",
        "        super().__init__()\n",
        "\n",
        "        self.size_in, self.size_out = size_in, size_out\n",
        "\n",
        "        # to keep control of the seed\n",
        "        #weights = np.random.randn(self.size_in, self.size_out)\n",
        "        self.V = nn.Parameter(torch.from_numpy(V).float(), requires_grad=True)\n",
        "        #self.V = weights.view(self.size_in, self.size_out)\n",
        "\n",
        "        # otherwise this is the correct weights init\n",
        "        #weights = torch.Tensor(size_out, size_in)\n",
        "        #self.W = nn.Parameter(weights, requires_grad=True)\n",
        "        #torch.nn.init.normal_(self.W, mean=0.0, std=1.0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        V = self.V.view(self.size_in, self.size_out)\n",
        "        #print(x, self.V)\n",
        "        out = torch.mm(x, self.V)\n",
        "        return out \n",
        "\n",
        "linearlay = MyLinearLayer(size_in, size_out)\n",
        "linearlay(conv_pytorch.view(1,4))\n",
        "\n",
        "# Let us check that it gives the same results as the numpy linear layer built before\n",
        "\n",
        "layer_1_act_vec = np.expand_dims(np.reshape(conv_numpy,-1),axis=0) # shape (1,4)\n",
        "layer_2 = layer_1_act_vec.dot(V) \n",
        "\n",
        "torch.tensor(layer_2) - linearlay(conv_pytorch.view(1,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.2410e-07]], dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3m0pKV027ew",
        "outputId": "08d3d098-e7eb-4654-b8a9-3fe154ad76b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "list(linearlay.parameters()), V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([Parameter containing:\n",
              "  tensor([[-1.0981],\n",
              "          [-1.1772],\n",
              "          [-0.2968],\n",
              "          [-1.6425]], requires_grad=True)], array([[-1.09807964],\n",
              "        [-1.17721229],\n",
              "        [-0.29675542],\n",
              "        [-1.64252144]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA5w4aummryu"
      },
      "source": [
        "So far we have built two custom layers. Now we will use them for our simple CNN that share the same structure of the numpy implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzTTTXfJoBVd"
      },
      "source": [
        "class MySimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MySimpleCNN, self).__init__()\n",
        "        self.conv2d = MyConv2dLayer(2,2)\n",
        "        self.linear = MyLinearLayer(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x_reshaped = x.view(1,1,3,3)\n",
        "        layer1_out = torch.tanh(self.conv2d(x)) # [1, 1, 2, 2]\n",
        "        layer1_out_flat = layer1_out.view(1, 4) # [1, 1, 4]\n",
        "        y_pred = torch.sigmoid(self.linear(layer1_out_flat))\n",
        "        return y_pred.squeeze(-1).squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VMmtYpZCtdw"
      },
      "source": [
        "Let us now check (again!) that the models (numpy and pytorch) give identical outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDZoqfYknfa9",
        "outputId": "d462bdac-055d-4a4f-e821-5e41757db2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = MySimpleCNN()\n",
        "list(model.parameters()), W, V\n",
        "\n",
        "# test pytorch model on image 0\n",
        "init_model_pred_pytorch = model(dataset[0].view(1, 1, 3, 3))\n",
        "\n",
        "# Diff initial model predictions (numpy vs pytorch)\n",
        "init_model_pred_pytorch - torch.tensor(init_model_pred_numpy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.0474e-08]], dtype=torch.float64, grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnCLvcy3DO5b"
      },
      "source": [
        "When we built the numpy training we used as loss function the mean square error. Let us check that the built-in PyTorch `nn.MSELoss()` return the same value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ttQXdNycA8",
        "outputId": "1d5cccee-b3a0-45db-bd5d-1ef889dd37f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_fn = nn.MSELoss(reduction = 'mean')\n",
        "pow((np.array([0.70]) - np.array([0.83])),2), loss_fn(torch.tensor([0.70]), torch.tensor([0.83]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.0169]), tensor(0.0169))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNXxvCM9DtJ6"
      },
      "source": [
        "Now we are ready to start the training using our customized PyTorch model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmwghXJ6tTH8",
        "outputId": "3e059258-1172-4738-a1ef-d8cb88e22462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Settings\n",
        "num_epoch = 100\n",
        "learning_rate = 0.5\n",
        "\n",
        "model = MySimpleCNN()\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction = 'mean')\n",
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use Adam; the optim package contains many other\n",
        "# optimization algorithms. The first argument to the Adam constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# ----- TRAINING -------\n",
        "for iter in range(num_epoch):\n",
        "    for i in range(len(dataset)):\n",
        "      \n",
        "      # set the correct shape for the image\n",
        "      image = dataset[i].view(1, 1, 3, 3)\n",
        "\n",
        "      model_pred = model(image)\n",
        "      #print(model_pred , Y[i])\n",
        "      \n",
        "      loss = loss_fn(model_pred, Y[i])\n",
        "\n",
        "      # Zero the gradients before running the backward pass.\n",
        "      model.zero_grad()\n",
        "\n",
        "      # Backward pass: compute gradient of the loss with respect to all the learnable\n",
        "      # parameters of the model. Internally, the parameters of each Module are stored\n",
        "      # in Tensors with requires_grad=True, so this call will compute gradients for\n",
        "      # all learnable parameters in the model.\n",
        "      loss.backward()\n",
        "\n",
        "      # In alternative of optimizer step using torch.optim:\n",
        "      # Update the weights using gradient descent (almost manually). Each parameter is a Tensor, so\n",
        "      # we can access its gradients like we did before.\n",
        "      # torch.no_grad(): it temporarily sets all the requires_grad flag to false. If we omit it,\n",
        "      # then weight update step will be added to the computation graph of the model which is not desired.\n",
        "      # This will simply update their values without changing their gradients.\n",
        "      with torch.no_grad(): \n",
        "          for param in model.parameters():\n",
        "              param -= learning_rate * param.grad\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHKA9Oj3jV9H"
      },
      "source": [
        "Let us now check the ouput differences between numpy and PyTorch approaches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Em49E1cLaoH",
        "outputId": "58ba01a3-5654-440b-b7c7-8f1ff0957083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.1872, -2.1565],\n",
              "         [ 0.4040, -0.2535]], requires_grad=True), Parameter containing:\n",
              " tensor([[-1.1267],\n",
              "         [-1.2058],\n",
              "         [-0.1355],\n",
              "         [-1.4813]], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_01qmdsbE-M"
      },
      "source": [
        "diff = list(model.parameters())[0].detach().numpy() - W_numpy\n",
        "\n",
        "assert all(v <= 1e-5 for v in diff.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_UQByoOhtks"
      },
      "source": [
        "diff = list(model.parameters())[1].detach().numpy() - V_numpy\n",
        "\n",
        "assert all(v <= 1e-5 for v in diff.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GsnFST-wVTE",
        "outputId": "a57e2a4c-03a6-4a26-bdc9-82820aaabf64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "res = []\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "  image = dataset[i].view(1, 1, 3, 3)\n",
        "  model_pred = model(image)\n",
        "  pred = model_pred.detach().numpy()\n",
        "  res.append(pred)\n",
        "\n",
        "print(res)\n",
        "print(Y.squeeze(-1).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array(0.50179565, dtype=float32), array(0.770482, dtype=float32), array(0.8813068, dtype=float32), array(0.97694844, dtype=float32)]\n",
            "[0.53 0.77 0.88 1.  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uVcbGiRI1s_"
      },
      "source": [
        "diff = list(res) - final_out  # final_out contains the predictions of the numpy model\n",
        "\n",
        "assert all(v <= 1e-5 for v in diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrEzaKtzLdMN"
      },
      "source": [
        "## PyTorch CNN Implementation II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgk-IVZ2nk2c"
      },
      "source": [
        "Below, we will repeat what done so far but \n",
        "\n",
        "* without using custom layers. We will use PyTorch built-in convolutional and linear layers: `nn.Conv2d()` and `cc.Linear()` ;\n",
        "\n",
        "* using `torch.optim` that will take care for us of stochastic gradient descend.\n",
        "\n",
        "Note: using `nn.Conv2d()` and `cc.Linear()`, we will not expect exact results with respect to previous cases. The reason is that, as mentioned above, built-in PyTorch functions have internal random initialization which, given a seed, is different from numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N84B-nFEn1F9"
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # PyTorch built-in conv2d and linear layers\n",
        "        self.conv2d = nn.Conv2d(1, 1, (2,2)) # channel_in, channel_out, kernel_size\n",
        "        self.linear = nn.Linear(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        layer1_out = torch.tanh(self.conv2d(x)) # [1, 1, 2, 2]\n",
        "        layer1_out_flat = layer1_out.view(1, 4) # [1, 1, 4]\n",
        "        y_pred = torch.sigmoid(self.linear(layer1_out_flat))\n",
        "        return y_pred.squeeze(-1).squeeze(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx1CvDLcWAdz",
        "outputId": "f47343a3-cd95-40e0-85ca-0f32a8fb2270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Settings\n",
        "num_epoch = 100\n",
        "learning_rate = 0.05\n",
        "\n",
        "model = SimpleCNN()\n",
        "\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction = 'mean')\n",
        "\n",
        "# Use the optim package to define an Optimizer that will update the weights of\n",
        "# the model for us. Here we will use Adam; the optim package contains many other\n",
        "# optimization algorithms. The first argument to the Adam constructor tells the\n",
        "# optimizer which Tensors it should update.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# ----- TRAINING -------\n",
        "for iter in range(num_epoch):\n",
        "    for i in range(len(dataset)):\n",
        "      \n",
        "      # set the correct shape for the image\n",
        "      image = dataset[i].view(1, 1, 3, 3)\n",
        "\n",
        "      model_pred = model(image)\n",
        "      #print(model_pred , Y[i])\n",
        "      \n",
        "      loss = loss_fn(model_pred, Y[i])\n",
        "\n",
        "      # Before the backward pass, use the optimizer object to zero all of the\n",
        "      # gradients for the variables it will update (which are the learnable\n",
        "      # weights of the model). This is because by default, gradients are\n",
        "      # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
        "      # is called. Checkout docs of torch.autograd.backward for more details.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # NOTE: What is the difference between model.zero_grad() and optimizer.zero_grad()?\n",
        "      # The distinction is useful when you have multiple models in the same optimizer, \n",
        "      # or multiple optimizer for different part of their model. In these cases you can have \n",
        "      # more freedom and choose what to zero grad.\n",
        "\n",
        "      # Backward pass: compute gradient of the loss with respect to model\n",
        "      # parameters\n",
        "      loss.backward()\n",
        "\n",
        "      # Calling the step function on an Optimizer makes an update to its\n",
        "      # parameters\n",
        "      optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:445: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXT6VE_VeK8U",
        "outputId": "6651fe2f-cbb0-4370-fc95-c49bd10761e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "res = []\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "  image = dataset[i].view(1, 1, 3, 3)\n",
        "  model_pred = model(image)\n",
        "  pred = model_pred.detach().numpy()\n",
        "  res.append(pred)\n",
        "\n",
        "print(res)\n",
        "print(Y.squeeze(-1).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array(0.529691, dtype=float32), array(0.7699678, dtype=float32), array(0.8840444, dtype=float32), array(0.97438216, dtype=float32)]\n",
            "[0.53 0.77 0.88 1.  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRIGJzTTonnB"
      },
      "source": [
        "That is great! In this case the results do not match exactly because of the different weights initialization of built-in PyTorch layers parameters."
      ]
    }
  ]
}